{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959603a7-d476-4018-86ef-317132bbe433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_groq_api_key\n",
    "groq_api_key = get_groq_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d52aec6-a82e-4fda-9e67-9baf7bdd4581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "# Loading PDF\n",
    "Loader=PyPDFLoader(\"Christopher_Nolan_Context.pdf\")\n",
    "data=Loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6b8c13-5e5b-42d2-aed9-c83b899d9e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Splitting long text into smaller chunks\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=300 , chunk_overlap=50)\n",
    "text= text_splitter.split_documents(data)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44abc4a1-f935-41ef-9057-690cfb945fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arbaz Aslam\\AppData\\Local\\Temp\\ipykernel_3512\\4036446368.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# Loading the Embeddinigs\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344c96ff-d4e5-4285-a1aa-61d04de4219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "# Store Chunks in vector DB\n",
    "\n",
    "db=FAISS.from_documents(text,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b9487-ff03-4c63-a8e3-7fa0dc35a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the moodel\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",  # choose the model you prefer\n",
    "    temperature=0.1,\n",
    "    max_tokens=512,                # adjust as per your context size\n",
    "    api_key=groq_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e07b64a-3425-473b-8ab9-568b2423f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# Creating RetrievaQA Chain\n",
    "\n",
    "chain = RetrievalQA.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df1def7-4153-4464-8d74-f252aae5dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask something about the PDf(or type 'exit'): \n",
      "\n",
      " who is Christoper Nolan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'who is Christoper Nolan?', 'result': 'Christopher Nolan is a British-American film director, producer, and screenwriter. He is widely regarded as one of the most influential and important filmmakers of the 21st century.', 'source_documents': [Document(id='12a80112-690f-4b9e-bc10-a27cc47be22c', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Christopher Nolan - Detailed Context\\nChristopher Nolan (born July 30, 1970) is a British-American film director, producer, and\\nscreenwriter widely regarded as one of the most influential and important filmmakers of the 21st'), Document(id='9ec2d4f0-b18e-4787-b14f-ac658e7ba908', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Collaborators Nolan commonly works with a group of trusted collaborators, producing a consistent\\naesthetic and quality across his films. Frequent collaborators include: - Emma Thomas (producer;\\nNolan\\'s wife and producing partner) - Hans Zimmer (composer for many films, including \"Inception\"'), Document(id='4ce7b299-3775-4e40-8660-86c407b62177', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='streaming has grown.\\nPersonal Notes and Public Image Nolan is known for being private and media-averse compared to\\nmany Hollywood directors. He rarely shares personal life details publicly. He has been an'), Document(id='1f167df0-4851-46f7-8d2c-19676efe5bd6', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content=\"ambiguity.\\nEarly Life and Education Nolan was born to an English father and American mother and raised in\\nLondon. From an early age he showed an interest in filmmaking, creating short films on his father's\")]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask something about the PDf(or type 'exit'): \n",
      "\n",
      " his famous movie?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'his famous movie?', 'result': 'Based on the provided context, one of Christopher Nolan\\'s most famous movies is \"Memento\" (2000). It\\'s a breakthrough film known for its reverse chronological storytelling about a man with short-term memory loss trying to find his wife\\'s killer.', 'source_documents': [Document(id='710d968a-4e05-4409-a7b0-0e00e272b228', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Recurring themes in his films include: - Time and temporality: films like \"Memento\", \"Interstellar\",\\nand \"Tenet\" play with the structure and perception of time. - Memory and identity: \"Memento\" and\\n\"Insomnia\" explore how memory shapes a person. - Moral ambiguity and duty: \"The Dark Knight\"'), Document(id='d8f220e0-06ef-433a-999d-91225f11fc41', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='and \"Interstellar\") - Wally Pfister (cinematographer on earlier films) - Lee Smith and later Jennifer\\nLame (editors) - Michael Caine, Cillian Murphy, Christian Bale, Joseph Gordon-Levitt, and Tom\\nHardy (actors who have appeared in multiple Nolan films)'), Document(id='b04a644b-ef86-4695-96b5-b45dd48d841f', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content=\"Super 8 camera. He studied English Literature at University College London, where he also made\\nstudent films and developed an interest in the technical and narrative sides of filmmaking.\\nDirecting Style and Themes Nolan's style blends intellectual puzzles with emotional storytelling. He\"), Document(id='cbb897df-7f4d-4614-9e92-b16c975b6963', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-09T08:01:05+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-09T08:01:05+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'Christopher_Nolan_Context.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content=\"student. It showcases his early interest in nonlinear narrative and suspense. - Memento (2000): A\\nbreakthrough film known for its reverse chronological storytelling about a man with short-term\\nmemory loss trying to find his wife's killer. - Insomnia (2002): A psychological thriller about guilt and\")]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask something about the PDf(or type 'exit'): \n",
      "\n",
      " exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query=input(\"Ask something about the PDf(or type 'exit'): \\n\\n\")\n",
    "    if query.lower()==\"exit\":\n",
    "        break\n",
    "    result=chain.invoke(query)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3242604-5407-443d-90bc-f35d2ef966d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arbaz Aslam\\AppData\\Local\\Temp\\ipykernel_6632\\1393255994.py:76: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat with your PDFs\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\fastapi\\applications.py\", line 1082, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\routing.py\", line 78, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\fastapi\\routing.py\", line 308, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\fastapi\\routing.py\", line 219, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\gradio\\routes.py\", line 1664, in get_upload_progress\n",
      "    await asyncio.wait_for(\n",
      "        file_upload_statuses.is_tracked(upload_id), timeout=3\n",
      "    )\n",
      "  File \"G:\\Anaconda\\Lib\\asyncio\\tasks.py\", line 507, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Users\\Arbaz Aslam\\AppData\\Roaming\\Python\\Python313\\site-packages\\gradio\\route_utils.py\", line 528, in is_tracked\n",
      "    return await self._signals[upload_id].wait()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"G:\\Anaconda\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"G:\\Anaconda\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x0000025436151250 [unset]> is bound to a different event loop\n",
      "C:\\Users\\Arbaz Aslam\\AppData\\Local\\Temp\\ipykernel_6632\\1393255994.py:58: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chat_chain({\"question\": message, \"chat_history\": chat_history})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# 🔑 Set your Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"GROQ_API_KEY\"\n",
    "\n",
    "chat_chain = None\n",
    "chat_history = []\n",
    "\n",
    "# 📘 Function to process uploaded PDF(s)\n",
    "def process_pdfs(pdf_files):\n",
    "    global chat_chain, chat_history\n",
    "\n",
    "    if not pdf_files:\n",
    "        return \"⚠️ Please upload at least one PDF file.\"\n",
    "\n",
    "    all_docs = []\n",
    "    for pdf in pdf_files:\n",
    "        pdf_path = pdf.name if hasattr(pdf, \"name\") else pdf  # Handle Gradio file object safely\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    # Split PDF text into chunks for better embedding\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=80)\n",
    "    chunks = splitter.split_documents(all_docs)\n",
    "\n",
    "    # Create vector database with embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    # Initialize Groq LLM\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.2)\n",
    "\n",
    "    # Build conversational retrieval chain\n",
    "    chat_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    chat_history = []\n",
    "    return \"✅ PDF processed successfully! You can now ask questions.\"\n",
    "\n",
    "# 💬 Function to chat with the processed PDFs\n",
    "def chat_with_pdfs(message, history):\n",
    "    global chat_chain, chat_history\n",
    "\n",
    "    if chat_chain is None:\n",
    "        return history + [[message, \"⚠️ Please upload and process a PDF first!\"]]\n",
    "\n",
    "    result = chat_chain({\"question\": message, \"chat_history\": chat_history})\n",
    "    answer = result[\"answer\"]\n",
    "\n",
    "    chat_history.append((message, answer))\n",
    "    history.append([message, answer])\n",
    "    return history\n",
    "\n",
    "# 🖥️ Build Gradio App\n",
    "with gr.Blocks(title=\"Chat with PDF\") as demo:\n",
    "    gr.Markdown(\"# 🤖 Chat with Your PDF\")\n",
    "    gr.Markdown(\"Upload one or more PDF files, process them, and ask questions interactively.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        pdf_files = gr.File(label=\"📂 Upload PDF(s)\", file_count=\"multiple\", file_types=[\".pdf\"])\n",
    "        process_button = gr.Button(\"⚙️ Process PDFs\")\n",
    "\n",
    "    status_box = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Chat with your PDFs\", height=400)\n",
    "    msg = gr.Textbox(label=\"💬 Ask a question\", placeholder=\"Type here and press Enter...\")\n",
    "    clear = gr.Button(\"🧹 Clear Chat\")\n",
    "\n",
    "    process_button.click(process_pdfs, inputs=[pdf_files], outputs=[status_box])\n",
    "    msg.submit(chat_with_pdfs, [msg, chatbot], [chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81b440-54ae-4a33-95ea-d43f0c652f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
